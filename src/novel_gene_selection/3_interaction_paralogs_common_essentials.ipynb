{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_CUTOFF = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "GENE_COM_ESS_MAP = \"results/candidate_genes/public_20Q2/gene-com_ess.dict\"\n",
    "ESSENTIAL_GENES  = 'results/essential_candidates/public_20Q2/essential_genes-all.pkl'\n",
    "\n",
    "PARALOG_DATA     = 'data/DGD/duplicate_genes_Hsapiens.tsv'\n",
    "PANTHER_MAP      = 'data/PANTHER/paralogs-GeneID'\n",
    "PANTHER_PARALOGS = 'data/PANTHER/paralogs'\n",
    "\n",
    "CORUM_DATA       = 'data/CORUM/allComplexes.txt'\n",
    "STRING_DATA      = 'data/STRING/9606.protein.links.full.v11.0.txt'\n",
    "STRING_MAP       = 'data/ens_entrez_maps/ensp_entrez_mapping.pkl'\n",
    "SIGNOR_DATA      = 'data/SIGNOR/geneID_interactions.pkl'\n",
    "HURI_DATA        = 'data/HuRI/HuRI.tsv'\n",
    "HURI_MAP         = 'data/ens_entrez_maps/ensg_entrez_mapping.pkl'\n",
    "\n",
    "NCBI_GENE_NAMES  = 'data/misc/ncbi_gene_names.pkl'\n",
    "\n",
    "# Output files\n",
    "RESULTS_FILE = \"results/essential_candidates/public_20Q2/essential_genes_annotated.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gene - common essential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GENE_COM_ESS_MAP, 'rb') as f:\n",
    "    gene_com_ess_map = pkl.load(f)\n",
    "gene_com_ess_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load genes essential in cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_genes = pd.read_pickle(ESSENTIAL_GENES)\n",
    "essential_genes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DGD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_gens = pd.read_csv(PARALOG_DATA, delimiter='\\t', index_col=9)\n",
    "dup_gens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PANTHER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panther_map = pd.read_csv(PANTHER_MAP, delimiter=' ', index_col=0)\n",
    "panther_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paralogs = pd.read_csv(PANTHER_PARALOGS, delimiter=' ', header=None, names=['gene', 'paralog'])\n",
    "paralogs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CORUM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_complexes = pd.read_csv(CORUM_DATA, delimiter='\\t')\n",
    "\n",
    "human_prot_complexes = prot_complexes.loc[prot_complexes['SWISSPROT organism'].str.match(\"Homo\")]\n",
    "human_prot_complexes['subunits(Entrez IDs)'] = [[int(idx.strip())\n",
    "                                                 for idx in x.split(';')\n",
    "                                                     if idx != 'None' and idx.strip() != '']\n",
    "                                                for x in human_prot_complexes['subunits(Entrez IDs)']]\n",
    "human_prot_complexes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corum_interactions = set(i for comp in human_prot_complexes['subunits(Entrez IDs)'].values \n",
    "                             for i in combinations(comp, 2))\n",
    "corum_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load STRING data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_interactions = pd.read_csv(STRING_DATA, delimiter=' ')\n",
    "\n",
    "def f(*args):\n",
    "    if len(args) < 1:\n",
    "        raise ValueError(\"Function must have at least one provided argument\")\n",
    "    return 1. - np.prod([1. - i for i in args], axis=0)\n",
    "\n",
    "prot_interactions['experiments_score']  = f(prot_interactions.experiments/1000, \n",
    "                                            prot_interactions.experiments_transferred/1000)\n",
    "prot_interactions['database_score']     = f(prot_interactions.database/1000, \n",
    "                                            prot_interactions.database_transferred/1000)\n",
    "prot_interactions['coexpression_score'] = f(prot_interactions.coexpression/1000, \n",
    "                                            prot_interactions.coexpression_transferred/1000)\n",
    "prot_interactions['interaction_score']  = f(prot_interactions.experiments_score, \n",
    "                                            prot_interactions.database_score, \n",
    "                                            prot_interactions.coexpression_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep interactions only if score >= threshold\n",
    "probable_prot_interactions = prot_interactions.loc[prot_interactions.interaction_score >= STRING_CUTOFF / 100, \n",
    "                                                   ['protein1', 'protein2', 'interaction_score']]\n",
    "probable_prot_interactions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "probable_prot_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(STRING_MAP, 'rb') as f:\n",
    "    string_map = pkl.load(f)\n",
    "dict(list(string_map.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_interactions = set((string_map[p1], string_map[p2])\n",
    "                          for p1, p2 in probable_prot_interactions[['protein1', 'protein2']].values \n",
    "                              if string_map[p1] != -1 and string_map[p2] != -1)\n",
    "string_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SIGNOR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SIGNOR_DATA, 'rb') as f:\n",
    "    signor_data = np.array(list(pkl.load(f)))\n",
    "signor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signor_interactions = set(map(tuple, signor_data))\n",
    "signor_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huri_data = pd.read_csv(HURI_DATA, delimiter='\\t', header=None).values\n",
    "huri_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HURI_MAP, 'rb') as f:\n",
    "    huri_map = pkl.load(f)\n",
    "dict(list(huri_map.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huri_interactions = set((huri_map[p1], huri_map[p2]) \n",
    "                        for p1, p2 in huri_data\n",
    "                            if huri_map[p1] != -1 and huri_map[p2] != -1)\n",
    "huri_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Analysis of essential genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get common essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, row in essential_genes.iterrows():\n",
    "    print(f\"{row.gene} ({idx}):\\t{gene_com_ess_map[int(idx)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paralogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_paralogs = {}\n",
    "\n",
    "for idx, row in essential_genes.iterrows():\n",
    "    p = set()  \n",
    "    if idx in panther_map.index:\n",
    "        uniprot = panther_map.loc[idx, 'uniprot']\n",
    "        if type(uniprot) != str:\n",
    "            uniprot = uniprot.values[0]\n",
    "            \n",
    "        p.update(panther_map.loc[panther_map.uniprot.isin(paralogs.loc[paralogs.paralog == uniprot , 'gene'])].index)\n",
    "        p.update(panther_map.loc[panther_map.uniprot.isin(paralogs.loc[paralogs.gene == uniprot, 'paralog'])].index)\n",
    "        \n",
    "    if idx in dup_gens.index:\n",
    "        p.update(dup_gens.loc[dup_gens.group_id == dup_gens.loc[idx, 'group_id']].index)\n",
    "    if -1 in p:\n",
    "        p.remove(-1)\n",
    "    gene_paralogs[idx] = p\n",
    "gene_paralogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for interaction between paralogs and common essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_interactions = corum_interactions.union(string_interactions).union(signor_interactions).union(huri_interactions)\n",
    "print(len(all_interactions))\n",
    "list(all_interactions)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict_of_lists(a, b, dic={}):\n",
    "    if a not in dic:\n",
    "        dic[a] = set()\n",
    "    dic[a].add(b)\n",
    "    \n",
    "interaction_dict = dict()\n",
    "for i, j in tqdm(all_interactions):\n",
    "    add_to_dict_of_lists(i, j, interaction_dict)\n",
    "    add_to_dict_of_lists(j, i, interaction_dict)\n",
    "    \n",
    "print(len(interaction_dict))\n",
    "dict(list(interaction_dict.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction(gene1, gene2):\n",
    "    if gene1 in interaction_dict:\n",
    "        return gene2 in interaction_dict[gene1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NCBI_GENE_NAMES, 'rb') as f:\n",
    "    ncbi_gene_names = pkl.load(f)\n",
    "\n",
    "def get_gene_name(geneID):\n",
    "    if geneID not in ncbi_gene_names:\n",
    "        Entrez.email = \"test@gmail.com\"\n",
    "        handle = Entrez.efetch(\"gene\", id=str(geneID), rettype=\"gene_table\", retmode=\"text\")\n",
    "        info = handle.readline().split()\n",
    "        name = info[0]\n",
    "        ncbi_gene_names[geneID] = f\"{name} ({geneID})\", f\"{' '.join(info[1:]).strip()}\"\n",
    "        with open(NCBI_GENE_NAMES, 'wb') as f:\n",
    "            pkl.dump(ncbi_gene_names, f)\n",
    "    return ncbi_gene_names[geneID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_paralogs_interact = {}\n",
    "gene_paralogs_com_ess_graph = {}\n",
    "\n",
    "for idx, row in tqdm(essential_genes.iterrows(), total=len(essential_genes)):\n",
    "#     print(f\"\\n{row.Name} ({idx}):\\n\\t{len(gene_paralogs[idx])} paralogs\\n\\t{len(gene_com_ess_map[idx])} comm. ess.\")\n",
    "    _any = 0\n",
    "    _all = 0\n",
    "    \n",
    "    _paralogs = []\n",
    "    _com_ess  = []\n",
    "    \n",
    "    remove  = []\n",
    "    dropped = False\n",
    "    \n",
    "#     if len(gene_com_ess_map[idx]) > 50:\n",
    "#         print(f\"{idx} interacts with too many common essentials ({len(gene_com_ess_map[idx])})!\")\n",
    "#         dropped = True\n",
    "    \n",
    "    for paralog in gene_paralogs[idx]:\n",
    "        p_start = time()\n",
    "        if paralog == idx:\n",
    "            print(f\"{row.gene} ({idx}) has itself marked as paralog!\")\n",
    "            remove.append(paralog)\n",
    "            if len(gene_paralogs[idx]) - len(remove) == 0:\n",
    "                dropped = True\n",
    "        else:\n",
    "            interactions = []\n",
    "            for com_ess in gene_com_ess_map[idx]:\n",
    "                if paralog == com_ess:\n",
    "                    print(f\"{row.gene} ({idx}) has the common essential {get_gene_name(com_ess)[0]} as paralog!\")\n",
    "                    remove.append(paralog)  # TODO: Moet dit wel? We kunnen hem ook uit de com_ess lijst halen.\n",
    "                    if len(gene_paralogs[idx]) - len(remove) == 0:\n",
    "                        print(f\"No paralogs left!\")\n",
    "                        dropped = True\n",
    "                else:    \n",
    "                    interactions.append(interaction(paralog, com_ess))\n",
    "                    if interactions[-1]:\n",
    "                        _paralogs.append(get_gene_name(paralog)[0])\n",
    "                        _com_ess.append(get_gene_name(com_ess)[0])\n",
    "                if dropped:\n",
    "                    break\n",
    "        if dropped:\n",
    "            break\n",
    "        _any += any(interactions)\n",
    "        _all += all(interactions)\n",
    "#         print(f\"\\tParalog {paralog} done after {(time()-p_start)/1000:.3f} s\")\n",
    "    for i in remove:\n",
    "        gene_paralogs[idx].remove(i)\n",
    "    if dropped:\n",
    "        print(f\"Dropping {row.gene} ({idx}) from essential genes list...\")\n",
    "        essential_genes.drop(idx, inplace=True)\n",
    "        continue\n",
    "    \n",
    "    gene_paralogs_interact[idx] = (float(_any)/len(gene_paralogs[idx]), float(_all)/len(gene_paralogs[idx]))\n",
    "    gene_paralogs_com_ess_graph[idx] = {\"paralogs\": _paralogs, \"com_ess\": _com_ess}\n",
    "        \n",
    "gene_paralogs_interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gene_paralogs_com_ess_graph[10006]['paralogs'])\n",
    "sum(['10152' in i for i in gene_paralogs_com_ess_graph[10006]['paralogs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100)\n",
    "results = {\"gene\": [], \n",
    "           \"geneID\": [], \n",
    "           \"n_paralogs\": [], \n",
    "           \"n_common_essentials\": [], \n",
    "           \"% paralogs interacting with any\": [], \n",
    "           \"% paralogs interacting with all\": [], \n",
    "           \"interaction_graph\": [],\n",
    "           \"paralogs\": [],\n",
    "           \"common_essentials\": [],\n",
    "           \"interacting_paralogs\": [],\n",
    "           \"interacting_common_essentials\": [],\n",
    "          }\n",
    "\n",
    "for idx, row in essential_genes.iterrows():\n",
    "    results[\"gene\"].append(row.gene)\n",
    "    results[\"geneID\"].append(idx)\n",
    "    results[\"n_paralogs\"].append(len(gene_paralogs[idx]))\n",
    "    results[\"n_common_essentials\"].append(len(gene_com_ess_map[idx]))\n",
    "    results[\"% paralogs interacting with any\"].append(int(gene_paralogs_interact[idx][0]*100))\n",
    "    results[\"% paralogs interacting with all\"].append(int(gene_paralogs_interact[idx][1]*100))\n",
    "    results[\"interaction_graph\"].append(gene_paralogs_com_ess_graph[idx])\n",
    "    results[\"paralogs\"].append(gene_paralogs[idx])\n",
    "    results[\"common_essentials\"].append(gene_com_ess_map[idx])\n",
    "    results[\"interacting_paralogs\"].append(set(p for p in gene_paralogs[idx] if any([str(p) in i for i in gene_paralogs_com_ess_graph[idx]['paralogs']])))\n",
    "    results[\"interacting_common_essentials\"].append(set(c for c in gene_com_ess_map[idx] if any([str(c) in i for i in gene_paralogs_com_ess_graph[idx]['com_ess']])))\n",
    "\n",
    "results = pd.DataFrame(results).set_index('geneID')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inf(geneID):\n",
    "    cs = gene_com_ess_map[geneID]\n",
    "    ps = gene_paralogs[geneID]\n",
    "    \n",
    "    print(\"Gene:\\t\"+'\\t'.join(get_gene_name(geneID)))\n",
    "    print(\"Com. ess.:\")\n",
    "    for c in cs:\n",
    "        print('\\t'+'\\t'.join(get_gene_name(c)))\n",
    "    print(\"Paralogs:\")\n",
    "    for p in ps:\n",
    "        print('\\t'+'\\t'.join(get_gene_name(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These graphs were used to visualize the interactions between paralogs and common essentials\n",
    "# In some cases the graphs are not visually very appealing, especially when there are a large number of genes involved\n",
    "\n",
    "def draw_graph(graph, idx):\n",
    "    df = pd.DataFrame(graph)\n",
    "    \n",
    "    B = nx.Graph()\n",
    "    B.add_nodes_from(df['com_ess'], bipartite=0)\n",
    "    B.add_nodes_from(df['paralogs'], bipartite=1)\n",
    "    B.add_weighted_edges_from(\n",
    "        [(row['paralogs'], row['com_ess'], 1) for idx, row in df.iterrows()], \n",
    "        weight='weight')\n",
    "\n",
    "    pos = {node:[0, i] for i, node in enumerate(df['paralogs'])}\n",
    "    pos.update({node:[20, i] for i, node in enumerate(df['com_ess'])})\n",
    "    nx.draw(B, pos, with_labels=False)\n",
    "    for p in pos:  # raise text positions\n",
    "        if len(pos) == 2:\n",
    "            pos[p][1] += .01\n",
    "#         elif len(pos) > \n",
    "        else:\n",
    "            pos[p][1] += len(pos)/10\n",
    "            \n",
    "    nx.draw_networkx_labels(B, pos)\n",
    "    \n",
    "    plt.margins(.3)\n",
    "    \n",
    "    plt.figtext(.5,1.12,f'Interaction network for gene {get_gene_name(idx)[0]}', fontsize=17, ha='center')\n",
    "    plt.figtext(.2,1.02,\"Paralogs\",fontsize=15,ha='center')\n",
    "    plt.figtext(.78,1.02,\"Common Essentials\",fontsize=15,ha='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, p_any, graph in results.loc[results.Gene.isin(pediatric_genes),\n",
    "                                     [\"GeneID\", \"% paralogs interacting with any\", \"interaction_graph\"]].values:\n",
    "    get_inf(idx)\n",
    "    if p_any > 0:\n",
    "        draw_graph(graph, idx)\n",
    "    else:\n",
    "        print(\"### No interactions betwen paralogs and common essentials ###\")\n",
    "    print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_pickle(RESULTS_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
