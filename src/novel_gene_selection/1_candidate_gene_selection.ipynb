{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn3\n",
    "from re import search\n",
    "from itertools import combinations\n",
    "from venn import venn\n",
    "from taigapy import TaigaClient\n",
    "import seaborn as sns\n",
    "tc = TaigaClient()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_CUTOFF = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "CORUM_DATA       = 'data/CORUM/allComplexes.txt'\n",
    "STRING_DATA      = 'data/STRING/9606.protein.links.full.v11.0.txt'\n",
    "SIGNOR_DATA      = 'data/SIGNOR/geneID_interactions.pkl'\n",
    "HURI_DATA        = 'data/HuRI/HuRI.tsv'\n",
    "PARALOG_DATA     = 'data/DGD/duplicate_genes_Hsapiens.tsv'\n",
    "PANTHER_PARALOGS = 'data/PANTHER/paralogs-GeneID'\n",
    "ENSP_ENTREZ_MAP  = 'data/ens_entrez_maps/ensp_entrez_mapping.pkl'\n",
    "ENSG_ENTREZ_MAP  = 'data/ens_entrez_maps/ensg_entrez_mapping.pkl'\n",
    "\n",
    "# Output directory\n",
    "SAVE_DIR = f\"results/candidate_genes/public_20Q2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get common essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_ess = tc.get(name='public-20q2-075d', version=22, file='Achilles_common_essentials')\n",
    "\n",
    "com_ess = pd.DataFrame(com_ess.gene.str.split(' ',1).tolist(), columns=['gene','geneID']).set_index('geneID')\n",
    "com_ess.index = com_ess.index.str.strip('()').astype(int)\n",
    "com_ess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CORUM protein complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corum_data = pd.read_csv(CORUM_DATA, delimiter='\\t')\n",
    "corum_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load STRING database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data = pd.read_csv(STRING_DATA, delimiter=' ')\n",
    "string_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed SIGNOR database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SIGNOR_DATA, 'rb') as f:\n",
    "    signor_data = np.array(list(pkl.load(f)))\n",
    "signor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuRI database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huri_data = pd.read_csv(HURI_DATA, delimiter='\\t', header=None)\n",
    "huri_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load duplicate gene data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_gens = pd.read_csv(PARALOG_DATA, delimiter='\\t')\n",
    "dup_gens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PANTHER paralog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paralogs = pd.read_csv(PANTHER_PARALOGS, delimiter=' ')\n",
    "paralogs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ensemble EnsProtID to EntrezID map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ENSP_ENTREZ_MAP, 'rb') as f:\n",
    "    ensp_entrez_map = pkl.load(f)\n",
    "dict(list(ensp_entrez_map.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ensemble EnsGeneID to EntrezID map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ENSG_ENTREZ_MAP, 'rb') as f:\n",
    "    ensg_entrez_map = pkl.load(f)\n",
    "dict(list(ensg_entrez_map.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Filter and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only human protein complexes\n",
    "human_prot_complexes = corum_data.loc[corum_data['SWISSPROT organism'].str.match(\"Homo\")]\n",
    "human_prot_complexes['subunits(Entrez IDs)'] = [[int(idx.strip()) for idx in x.split(';') \n",
    "                                                 if idx.strip() != 'None' and idx.strip() != ''] \n",
    "                                                for x in human_prot_complexes['subunits(Entrez IDs)']]\n",
    "human_prot_complexes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(*args):\n",
    "    if len(args) < 1:\n",
    "        raise ValueError(\"Function must have at least one provided argument\")\n",
    "    return 1. - np.prod([1. - i for i in args], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get custom interaction score from STRING database by summing probabilities\n",
    "prot_interactions = string_data\n",
    "prot_interactions['experiments_score']  = f(prot_interactions.experiments/1000, \n",
    "                                            prot_interactions.experiments_transferred/1000)\n",
    "prot_interactions['database_score']     = f(prot_interactions.database/1000, \n",
    "                                            prot_interactions.database_transferred/1000)\n",
    "prot_interactions['coexpression_score'] = f(prot_interactions.coexpression/1000, \n",
    "                                            prot_interactions.coexpression_transferred/1000)\n",
    "prot_interactions['interaction_score']  = f(prot_interactions.experiments_score, \n",
    "                                            prot_interactions.database_score,\n",
    "                                            prot_interactions.coexpression_score)\n",
    "\n",
    "# Keep interactions only if score >= threshold\n",
    "probable_prot_interactions = prot_interactions.loc[prot_interactions.interaction_score >= STRING_CUTOFF / 100, \n",
    "                                                   ['protein1', 'protein2', 'interaction_score']]\n",
    "probable_prot_interactions.reset_index(drop=True, inplace=True)\n",
    "probable_prot_interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Find interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'CORUM':  {'DGD': set(), 'PANTHER': set()}, \n",
    "           'STRING': {'DGD': set(), 'PANTHER': set()}, \n",
    "           'SIGNOR': {'DGD': set(), 'PANTHER': set()},\n",
    "           'HuRI':   {'DGD': set(), 'PANTHER': set()},\n",
    "          }\n",
    "gene_com_ess_int = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def com_ess_interaction(com_ess, gene):   \n",
    "    if gene != com_ess:\n",
    "        if gene not in gene_com_ess_int.keys():\n",
    "            gene_com_ess_int[gene] = set()\n",
    "        gene_com_ess_int[gene].add(com_ess)\n",
    "    return gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_prots(ppi_list, common_essentials=com_ess.index.values):\n",
    "    candidates = [com_ess_interaction(p1, p2) if p1 in common_essentials else com_ess_interaction(p2, p1)\n",
    "                  for p1, p2 in tqdm(ppi_list)\n",
    "                      if bool(p1 in common_essentials) != bool(p2 in common_essentials)]\n",
    "    \n",
    "    # Make one single list of the candidate proteins which are not an already known essential dependency\n",
    "    candidates = set(candidates).difference(common_essentials)\n",
    "    print(len(candidates), \"candidates found\")\n",
    "    \n",
    "    # Check for paralogs\n",
    "    dgd     = set(dup_gens.loc[dup_gens.GeneID.isin(candidates)].GeneID)\n",
    "    panther = set(paralogs.loc[paralogs.GeneID.isin(candidates)].GeneID)\n",
    "    print(f\"DGD: {len(dgd)}, PANTHER: {len(panther)}, total: {len(dgd.union(panther))}\")\n",
    "    \n",
    "    return dgd, panther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select from CORUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corum_interactions = set(i for comp in human_prot_complexes['subunits(Entrez IDs)'].values \n",
    "                             for i in combinations(comp, 2))\n",
    "results['CORUM']['DGD'], results['CORUM']['PANTHER'] = get_candidate_prots(corum_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select from STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_interactions = set((ensp_entrez_map[p1], ensp_entrez_map[p2]) \n",
    "                              for p1, p2 in probable_prot_interactions[['protein1', 'protein2']].values \n",
    "                                  if ensp_entrez_map[p1] != -1 and ensp_entrez_map[p2] != -1)\n",
    "results['STRING']['DGD'], results['STRING']['PANTHER'] = get_candidate_prots(string_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select from SIGNOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['SIGNOR']['DGD'], results['SIGNOR']['PANTHER'] = get_candidate_prots(signor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select from HuRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huri_interactions = set((ensg_entrez_map[p1], ensg_entrez_map[p2]) \n",
    "                              for p1, p2 in huri_data.values\n",
    "                                  if ensg_entrez_map[p1] != -1 and ensg_entrez_map[p2] != -1)\n",
    "results['HuRI']['DGD'], results['HuRI']['PANTHER'] = get_candidate_prots(huri_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, paralog_sets in results.items():\n",
    "    for paralog_set, genes in paralog_sets.items():\n",
    "        print(f\"{dataset}-{paralog_set}: {len(genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 9), dpi=124, facecolor='w', edgecolor='k')\n",
    "# plt.title('Overlap between candidate genes from CORUM, HuRI, SIGNOR and STRING', fontsize=18)\n",
    "datasets = {f\"CORUM ({len(results['CORUM']['PANTHER'].union(results['CORUM']['DGD']))})\": results['CORUM']['PANTHER'].union(results['CORUM']['DGD']),\n",
    "            f\"HuRI ({len(results['HuRI']['PANTHER'].union(results['HuRI']['DGD']))})\": results['HuRI']['PANTHER'].union(results['HuRI']['DGD']),\n",
    "            f\"SIGNOR ({len(results['SIGNOR']['PANTHER'].union(results['SIGNOR']['DGD']))})\": results['SIGNOR']['PANTHER'].union(results['SIGNOR']['DGD']),\n",
    "            f\"STRING ({len(results['STRING']['PANTHER'].union(results['STRING']['DGD']))})\": results['STRING']['PANTHER'].union(results['STRING']['DGD']),\n",
    "           }\n",
    "venn(datasets, ax=plt.gca(), cmap=['r', 'g', 'b', 'y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5), dpi=124, facecolor='w', edgecolor='k')\n",
    "# plt.title('Overlap between candidate genes found through PANTHER and DGD')\n",
    "venn2([results['CORUM']['PANTHER'].union(results['STRING']['PANTHER']).union(results['SIGNOR']['PANTHER']).union(results['HuRI']['PANTHER']), \n",
    "       results['CORUM']['DGD'].union(results['STRING']['DGD']).union(results['SIGNOR']['DGD']).union(results['HuRI']['DGD'])], \n",
    "      set_labels=[f\"PANTHER ({len(results['CORUM']['PANTHER'].union(results['STRING']['PANTHER']).union(results['SIGNOR']['PANTHER']).union(results['HuRI']['PANTHER']))})\", \n",
    "                  f\"DGD ({len(results['CORUM']['DGD'].union(results['STRING']['DGD']).union(results['SIGNOR']['DGD']).union(results['HuRI']['DGD']))})\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save candidate genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "for dataset, paralog_sets in results.items():\n",
    "    for paralog_set, genes in paralog_sets.items():\n",
    "        with open(os.path.join(save_dir, f\"{dataset}-{paralog_set}\"), 'w') as f:\n",
    "            for gene in genes:\n",
    "                f.write(f\"{gene}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save gene - common essential mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"gene-com_ess.dict\"), \"wb\") as f:\n",
    "    pkl.dump(gene_com_ess_int, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
